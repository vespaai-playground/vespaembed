# Triplets task with Unsloth
# Faster full fine-tuning with Unsloth optimizations

task: triplets
base_model: sentence-transformers/all-MiniLM-L6-v2

data:
  train: ./examples/data/triplets.csv

training:
  epochs: 3
  batch_size: 32
  learning_rate: 2e-5
  warmup_ratio: 0.1
  weight_decay: 0.01
  bf16: true
  optimizer: adamw_torch
  scheduler: linear
  eval_steps: 500
  save_steps: 500
  logging_steps: 100

output:
  push_to_hub: false

gradient_checkpointing: true

unsloth:
  enabled: true
  save_method: merged_16bit
